# Query Expansion Explanation

## Dataset
The dataset required for this project can be downloaded from the following link:  
[Dataset Link](https://drive.google.com/file/d/19qkzLYnz7NiE4KeqO9ZQ2YGtSB9QBcL1/view?usp=sharing)

## Dependencies
This project depends on several packages, including:
- [pylucene-10.0.0](https://dlcdn.apache.org/lucene/pylucene/)
- [pytrec_eval](https://github.com/cvangysel/pytrec_eval)
- tqdm (for progress bars)

To install the necessary dependencies, run:
```bash
pip install pytrec_eval tqdm scipy numpy
```
Additionally, GNU `parallel` is required, which is available in the standard repositories of most Linux distributions.

## Preliminary Results
For queries generated by `iqg.py`, the `trec_eval` results are as follows:

*(Results are for the ideal query generated from the complete ground truth.)*
```
runid                 	all	ideal_query
num_q                 	all	249
num_ret               	all	249000
num_rel               	all	17412
num_rel_ret           	all	16213
map                   	all	0.8919
gm_map                	all	0.8817
Rprec                 	all	0.8511
bpref                 	all	0.8955
recip_rank            	all	1.0000
iprec_at_recall_0.00  	all	1.0000
iprec_at_recall_0.10  	all	0.9985
iprec_at_recall_0.20  	all	0.9957
iprec_at_recall_0.30  	all	0.9900
iprec_at_recall_0.40  	all	0.9789
iprec_at_recall_0.50  	all	0.9564
iprec_at_recall_0.60  	all	0.9293
iprec_at_recall_0.70  	all	0.8905
iprec_at_recall_0.80  	all	0.8262
iprec_at_recall_0.90  	all	0.6921
iprec_at_recall_1.00  	all	0.3817
P_5                   	all	0.9912
P_10                  	all	0.9643
P_15                  	all	0.9266
P_20                  	all	0.8855
P_30                  	all	0.8100
P_100                 	all	0.4510
P_200                 	all	0.2718
P_500                 	all	0.1236
P_1000                	all	0.0651
```

---

# Steps to Reproduce for Restricted Ground Truth
These steps describe how to generate a restricted ground truth using only the relevance of documents that appear in the top 1000 retrieved documents.

### 1. Download and Extract the Dataset
Download the dataset from the provided link, extract it, and move it to a directory named `collections`:
```bash
mkdir -p collections
tar -xvzf trec678rb.tar.gz
mv trec678rb collections
```

### 2. Index the Dataset
```bash
python3 indexer_trec678rb.py
```
This will create an index in `indexed/trec678rb`.

### 3. Generate a `run` File for the Top 1000 BM25 Retrieval Results
```bash
python3 searcher.py
```
This will generate the `run` file at `test-runs/bm25.run`.

### 4. Intersect the `run` File with the Original `qrel` File
```bash
python3 intersect_run_with_qrel.py test-runs/bm25.run qrels/trec678rb.qrel qrels/bm25_intersect_trec678rb.qrel
```
This produces a restricted `qrel` file: `qrels/bm25_intersect_trec678rb.qrel`.

---

## Ideal Queries
[Download Ideal Queries](https://drive.google.com/file/d/1f2nzHYwQEDosw5UQQ4MtA-fm1mihNFLS/view?usp=sharing)

### Extracting the Ideal Queries
```bash
tar -xvzf ideal-queries.tar.gz
```

### Generating Ideal Queries
#### Method 1: Without Parallelization (Clean Output)
```bash
python3 iqg.py extracted-queries/trec678 --runid ideal_query_restrict
```
This produces:
- `ideal-queries/trec678/runs/ideal_query_restrict.run`
- `ideal-queries/trec678/weights/ideal_query_restrict.term_weights`

#### Method 2: With Parallelization
```bash
./parallel_ideal_query_computer <number_of_jobs>
```
*(Default: 12 parallel jobs)*

Merge the split files into a single `run` and `term_weights` file:
```bash
python3 split_dir_merger.py ideal-queries/trec678/runs/ideal_query_restrict-split ideal-queries/trec678/runs/ideal_query_restrict.run
```
```bash
python3 split_dir_merger.py ideal-queries/trec678/weights/ideal_query_restrict-split ideal-queries/trec678/weights/ideal_query_restrict.term_weights
```

Generate the `ap` file:
```bash
mkdir -p ideal-queries/trec678/aps/
trec_eval -m map -q qrels/trec678rb.qrel ideal-queries/trec678/runs/ideal_query_restrict.run > ideal-queries/trec678/aps/ideal_query_restrict.ap
sed -Ei 's/[[:blank:]]+/\t/g' ideal-queries/trec678/aps/*
```
(_The last line makes sure that for each line in the generated ap file, there is only one tabspace as the delimeter. This is required for `csv.reader` with delimiter `\t` to work._)

---

## Expanded Queries
[Download Expanded Queries](https://drive.google.com/file/d/1OcH57z-IqLs2bVgw5rKXiD5XkzhrgmFy/view?usp=sharing)

### Extracting the Expanded Queries
```bash
tar -xvzf expanded-queries.tar.gz
```

### Generating `run` and `ap` Files (Optional)
Expanded query weights were taken provided by Sourav Da ([expanded-queries-weights-only](https://drive.google.com/file/d/1PutRi-rUFQ0a4QfJ157lfHK1VXOmf3hk/view?usp=sharing))  and `run` and `ap` files were generated using `run_ap_generator.py`.

Parallel computation can be done using:
```bash
./parallel_run_ap_generator <number_of_jobs>
```
*(Default: 12 parallel jobs)*

---

## Computing Similarity and Correlation
No modifications were made to these scripts apart from input/output filenames. The similarity-correlation computations can be run as follows:
```bash
cd similarity-correlation
python3 compute-correlation-mm.py <similarity_measure>
```
where `<similarity_measure>` can be one of:
`'j', 'j1', 'j2', 'l1', 'l2', 'n', 'n1', 'n2'`.

---

# Results
## `jaccard` Similarity
| Correlation | Vanilla Ideal Query | Restricted Ideal Query |
|-------------|---------------------|------------------------|
| Pearson     | 0.27530978584589544 | 0.26719890865599216 |
| Kendall     | 0.2039317057781643 | 0.19527271741380392 |
| Spearman    | 0.2804058431142231 | 0.2676524936238417 |

## `l1` similarity
| Correlation | Vanilla Ideal Query | Restricted Ideal Query |
|-------------|---------------------|------------------------|
| Pearson     | -0.021846086059143458 | -0.013452476593593514 |
| Kendall     | -0.07218926465331622 | -0.06674220854442578 |
| Spearman    | -0.10172536810824717 | -0.09632707167480746 |

## `l2` similarity
| Correlation | Vanilla Ideal Query | Restricted Ideal Query |
|-------------|---------------------|------------------------|
| Pearson     | 0.3035792866335904 | 0.2983063348444898 |
| Kendall     | 0.29638548155480743 | 0.2845539556187513 |
| Spearman    | 0.39024597207486517 | 0.37373457259699033 |

## `ndcg_modified2` similarity
| Correlation | Vanilla Ideal Query | Restricted Ideal Query |
|-------------|---------------------|------------------------|
| Pearson     | 0.023741949357671686 | 0.03337957897785733 |
| Kendall     | 0.05391125458798632 | 0.050904183098999765 |
| Spearman    | 0.07306139152559063 | 0.06812348885506235 |
